{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Concepts Behind Data Loading  for IEMOCAP  Data\n",
    "\n",
    "## Introduction\n",
    "This document provides a mathematical explanation of the key operations used in the dataset loading process for multimodal emotion recognition, specifically in the `IEMOCAPDataset` class. The dataset integrates text, audio, and visual features for deep learning models. Below are the main mathematical concepts underlying the data loading process.\n",
    "\n",
    "## 1. Tensor Representation\n",
    "PyTorch utilizes tensors, which are multi-dimensional arrays, to store and process data efficiently. Mathematically, a tensor is an extension of a matrix to higher dimensions:\n",
    "\n",
    "$$[\n",
    "\\mathbf{T} \\in \\mathbb{R}^{d_1 \\times d_2 \\times \\dots \\times d_n}\n",
    "]$$\n",
    "\n",
    "where $$(d_i)$$ represents the size of each dimension. \n",
    "\n",
    "In the code, textual, audio, and visual features are converted into PyTorch tensors:\n",
    "\n",
    "```python\n",
    "text_features = torch.tensor(np.array(self.videoText[vid]), dtype=torch.float32)\n",
    "visual_features = torch.tensor(np.array(self.videoVisual[vid]), dtype=torch.float32)\n",
    "audio_features = torch.tensor(np.array(self.videoAudio[vid]), dtype=torch.float32)\n",
    "```\n",
    "\n",
    "**Reference:** [PyTorch Documentation on Tensors](https://pytorch.org/docs/stable/tensors.html)\n",
    "\n",
    "## 2. Sequence Padding (Handling Variable-Length Data)\n",
    "Sequences of different lengths must be padded to be processed in batches. Mathematically, padding transforms an input sequence \\( S \\) of varying length $$( l_i )$$ to a fixed length $$( L )$$:\n",
    "\n",
    "$$[\n",
    "S_i' = \\begin{cases} S_i, & \\text{if } |S_i| = L \\\\ S_i \\cup P, & \\text{if } |S_i| < L \\end{cases}\n",
    "]$$\n",
    "\n",
    "where \\( P \\) is a padding vector (e.g., zeros). This is implemented in PyTorch using:\n",
    "\n",
    "```python\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "```\n",
    "\n",
    "**Reference:** [PyTorch Documentation on Sequence Padding](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html)\n",
    "\n",
    "## 3. One-Hot Encoding for Speaker Information\n",
    "The speaker of each utterance is encoded as a one-hot vector:\n",
    "\n",
    "$$[\n",
    "\\mathbf{s} = \\begin{cases} [1, 0], & \\text{if speaker is Male} \\\\ [0, 1], & \\text{if speaker is Female} \\end{cases}\n",
    "]$$\n",
    "\n",
    "This ensures that speaker identity is represented in a format that neural networks can process:\n",
    "\n",
    "```python\n",
    "speaker_info = torch.FloatTensor([[1,0] if x=='M' else [0,1] for x in self.videoSpeakers[vid]])\n",
    "```\n",
    "\n",
    "**Reference:** [One-Hot Encoding Explained](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "\n",
    "## Conclusion\n",
    "These mathematical operations—tensor representation, sequence padding, and one-hot encoding—enable efficient loading of multimodal emotion recognition data in PyTorch. This preprocessing ensures that models can handle different sequence lengths and speaker information correctly, leading to better performance in emotion recognition tasks.\n",
    "\n",
    "For more details, refer to the provided links to official documentation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
