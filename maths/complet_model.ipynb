{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DialogueGCN: Mathematical Foundations & Implementation Deep Dive\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "1. [Core Architecture](#core-architecture)\n",
    "2. [Loss Functions](#loss-functions)\n",
    "3. [Attention Mechanisms](#attention-mechanisms)\n",
    "4. [Recurrent Components](#recurrent-components)\n",
    "5. [Graph Neural Network Components](#graph-neural-network-components)\n",
    "6. [Feature Extraction](#feature-extraction)\n",
    "7. [Key Papers & References](#key-papers--references)\n",
    "\n",
    "## Core Architecture\n",
    "\n",
    "The DialogueGCN model combines three fundamental neural paradigms:\n",
    "\n",
    "1. **Sequential Processing** (RNN/LSTM/GRU)\n",
    "2. **Graph Neural Networks** (RGCN)\n",
    "3. **Attention Mechanisms**\n",
    "\n",
    "Mathematically, the full model can be represented as:\n",
    "\n",
    "$$\n",
    "\\text{Emotion} = \\text{GNN}(\\text{RGCN}(\\text{SeqEncoder}(U, qmask), \\mathcal{G}(V,E)))\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $U$: Utterance sequence\n",
    "- $qmask$: Speaker masks\n",
    "- $\\mathcal{G}$: Dialogue graph construction\n",
    "\n",
    "[Original Paper](https://arxiv.org/abs/1908.11540) | [Official Code](https://github.com/declare-lab/conv-emotion)\n",
    "\n",
    "## Loss Functions\n",
    "\n",
    "### MaskedNLLLoss\n",
    "```python\n",
    "class MaskedNLLLoss(nn.Module):\n",
    "    def forward(self, pred, target, mask):\n",
    "        mask_ = mask.view(-1,1)\n",
    "        loss = self.loss(pred * mask_, target) / torch.sum(mask)\n",
    "```\n",
    "Mathematics:\n",
    "$$\n",
    "L = - \\frac{\\sum_{t=1}^{T} m_t \\cdot y_t \\log(p_t)}{\\sum_{t=1}^{T} m_t}\n",
    "$$\n",
    "Where $m_t$ is the mask value at position $t$.\n",
    "\n",
    "**Use Case:** Handles variable-length sequences in dialogue systems.\n",
    "\n",
    "**References:**\n",
    "- [PyTorch NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html)\n",
    "- Sequence Masking Explained\n",
    "\n",
    "### MaskedMSELoss\n",
    "```python\n",
    "class MaskedMSELoss(nn.Module):\n",
    "    def forward(self, pred, target, mask):\n",
    "        loss = self.loss(pred * mask, target) / torch.sum(mask)\n",
    "```\n",
    "Mathematics:\n",
    "$$\n",
    "L = \\frac{\\sum_{t=1}^{T} m_t \\cdot (y_t - \\hat{y}_t)^2}{\\sum_{t=1}^{T} m_t}\n",
    "$$\n",
    "\n",
    "**Use Case:** Regression tasks with incomplete sequences.\n",
    "\n",
    "**References:**\n",
    "- [MSELoss Docs](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html)\n",
    "\n",
    "## Attention Mechanisms\n",
    "\n",
    "### SimpleAttention\n",
    "```python\n",
    "scale = self.scalar(M) # seq_len, batch, 1\n",
    "alpha = F.softmax(scale, dim=0)\n",
    "```\n",
    "Mathematics:\n",
    "$$\n",
    "\\alpha_i = \\text{softmax}(W h_i)\n",
    "$$\n",
    "$$\n",
    "c = \\sum_i \\alpha_i h_i\n",
    "$$\n",
    "\n",
    "**Visualization:**\n",
    "```\n",
    "[Utter1] --α1--> [Context]\n",
    "[Utter2] --α2--> [Context]\n",
    "[Utter3] --α3--> [Context]\n",
    "```\n",
    "\n",
    "**References:**\n",
    "- [Attention Mechanisms Survey](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "### MatchingAttention\n",
    "Implements three attention variants:\n",
    "- **Dot Product:** $e_{ij} = q^T k_j$\n",
    "- **General:** $e_{ij} = q^T W k_j$\n",
    "- **Concat:** $e_{ij} = v^T \\text{tanh}(W[q; k_j])$\n",
    "\n",
    "**Code Reference:** Lines 89-143\n",
    "\n",
    "**Paper Reference:** Luong et al. (2015)\n",
    "\n",
    "## Recurrent Components\n",
    "\n",
    "### DialogueRNNCell\n",
    "```python\n",
    "self.g_cell = nn.GRUCell(D_m+D_p, D_g)  # Global state\n",
    "self.p_cell = nn.GRUCell(D_m+D_g, D_p)  # Party state\n",
    "self.e_cell = nn.GRUCell(D_p, D_e)      # Emotion state\n",
    "```\n",
    "Mathematical Formulation:\n",
    "- **Global GRU:** $g_t = \\text{GRU}([u_t, p_{t-1}^{speaker}])$\n",
    "- **Party GRU:** $p_t = \\text{GRU}([u_t, c_t])$\n",
    "- **Emotion GRU:** $e_t = \\text{GRU}(p_t^{speaker})$\n",
    "\n",
    "**Reference:** [DialogueRNN Paper](https://arxiv.org/abs/1811.00405)\n",
    "\n",
    "## Graph Neural Network Components\n",
    "\n",
    "### RGCN Layer\n",
    "```python\n",
    "self.conv1 = RGCNConv(num_features, hidden_size, num_relations)\n",
    "```\n",
    "Message Passing:\n",
    "$$\n",
    "h_i^{(l+1)} = \\sigma \\left( \\sum_{r \\in R} \\sum_{j \\in N_r(i)} \\frac{1}{c_{i,r}} W_r^{(l)} h_j^{(l)} \\right)\n",
    "$$\n",
    "\n",
    "**Edge Type Handling:**\n",
    "- $2 \\times n_{speakers}^2$ edge types (forward/backward × speaker pairs)\n",
    "- Basis decomposition for parameter efficiency\n",
    "\n",
    "**Official Docs:** [RGCNConv](https://arxiv.org/abs/1703.06103)\n",
    "\n",
    "### Graph Construction\n",
    "```python\n",
    "def batch_graphify(features, qmask, lengths, ...):\n",
    "    # Creates edges based on:\n",
    "    # 1. Temporal window\n",
    "    # 2. Speaker information\n",
    "```\n",
    "**Edge Formation Rules:**\n",
    "- Temporal edges within $[t-w_{past}, t+w_{future}]$\n",
    "- Speaker-aware edges (different types for same/different speakers)\n",
    "- Direction-aware edges (forward/backward in dialogue)\n",
    "\n",
    "## Feature Extraction\n",
    "\n",
    "### CNN Feature Extractor\n",
    "```python\n",
    "self.convs = nn.ModuleList([\n",
    "    nn.Conv1d(embedding_dim, filters, K)\n",
    "    for K in kernel_sizes\n",
    "])\n",
    "```\n",
    "**Operation Pipeline:**\n",
    "1. Embedding lookup\n",
    "2. Multi-width 1D convolutions (3,4,5 grams)\n",
    "3. Max-pooling over time\n",
    "4. Feature projection\n",
    "\n",
    "**Reference:** Kim (2014) - CNN for Text\n",
    "\n",
    "## Key Papers & References\n",
    "\n",
    "### DialogueGCN:\n",
    "- [Paper](https://arxiv.org/abs/1908.11540)\n",
    "- [Code](https://github.com/declare-lab/conv-emotion)\n",
    "\n",
    "### Graph Networks:\n",
    "- Kipf & Welling (2017) - GCN\n",
    "- Schlichtkrull et al. (2018) - RGCN\n",
    "\n",
    "### Attention:\n",
    "- Vaswani et al. (2017) - Transformers\n",
    "- Luong et al. (2015) - Global Attention\n",
    "\n",
    "### Dialogue Systems:\n",
    "- [DialogueRNN](https://arxiv.org/abs/1811.00405)\n",
    "- ICON\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
