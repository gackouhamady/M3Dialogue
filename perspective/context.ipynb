{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amélioration de DialogueGCN pour un Contexte Dynamique\n",
    "\n",
    "## Problème  \n",
    "DialogueGCN a une modélisation statique du contexte, ce qui limite sa capacité à capturer les nuances des émotions dans les conversations, notamment pour les interventions courtes (\"okay\", \"oui\", etc.).\n",
    "\n",
    "## Solution  \n",
    "Intégrer un mécanisme d’attention temporelle adaptative et un renforcement contextuel pour améliorer la flexibilité du modèle.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Parties du Code à Modifier\n",
    "\n",
    "### (A) Mécanisme d’Attention Statique → Dynamique  \n",
    "- **Fichier** : `models.py`  \n",
    "- **Lignes concernées** : 516–616 (MaskedEdgeAttention)  \n",
    "- **Méthodes** : `forward()` (l. 538) - Calcul des scores d’attention fixes.  \n",
    "  \n",
    "#### **Modification proposée** :  \n",
    "```python\n",
    "class AdaptiveTemporalAttention(nn.Module):\n",
    "    def __init__(self, input_dim, max_seq_len, no_cuda):\n",
    "        super().__init__()\n",
    "        self.time_attn = nn.MultiheadAttention(input_dim, num_heads=4)  # Attention dynamique\n",
    "        self.pos_encoder = PositionalEncoding(input_dim)  # Ajoute la temporalité\n",
    "\n",
    "    def forward(self, M, lengths, edge_ind):\n",
    "        M = self.pos_encoder(M)  # (seq_len, batch, D_e)\n",
    "        attn_output, _ = self.time_attn(M, M, M)  # Recalcule les poids à chaque pas\n",
    "        scores = self.compute_adaptive_scores(attn_output, edge_ind)  # Nouvelle méthode\n",
    "        return scores\n",
    "```\n",
    "#### **Avantages** :\n",
    "✅ Adaptation en temps réel aux changements conversationnels.  \n",
    "✅ Remplace l’ancienne attention par une version basée sur Transformer.  \n",
    "\n",
    "---\n",
    "\n",
    "### (B) Fenêtres Temporelles Fixes → Adaptatives  \n",
    "- **Fichier** : `models.py`  \n",
    "- **Lignes concernées** : 619–720 (batch_graphify et edge_perms)  \n",
    "- **Méthodes** : `edge_perms()` (l. 619) - Définit des fenêtres fixes (`window_past`, `window_future`).  \n",
    "  \n",
    "#### **Modification proposée** :  \n",
    "```python\n",
    "def dynamic_edge_perms(l, current_utterance, hidden_state, max_window=10):\n",
    "    \"\"\" Prédit la fenêtre optimale en fonction du contexte. \"\"\"\n",
    "    window_size = self.window_predictor(current_utterance, hidden_state).clamp(1, max_window)\n",
    "    return custom_edge_perms(l, window_size)\n",
    "```\n",
    "#### **Intégration** :  \n",
    "- Remplacer `edge_perms` par `dynamic_edge_perms` dans `batch_graphify`.\n",
    "- Ajouter un prédicteur de fenêtre (MLP) :  \n",
    "```python\n",
    "self.window_predictor = nn.Sequential(\n",
    "    nn.Linear(D_e + D_h, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1)\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### (C) Renforcement Contextuel pour Mots Courts  \n",
    "- **Fichier** : `models.py`  \n",
    "- **Lignes concernées** : 723–875 (DialogueGCNModel)  \n",
    "- **Méthodes** : `forward()` (l. 832) - Traitement des features sans adaptation contextuelle.  \n",
    "  \n",
    "#### **Modification proposée** :  \n",
    "```python\n",
    "class ContextEnhancer(nn.Module):\n",
    "    def __init__(self, D_e):\n",
    "        super().__init__()\n",
    "        self.enhancer = nn.Sequential(\n",
    "            nn.Linear(D_e * 2, D_e),  # Concatène utterance + contexte\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(D_e, D_e))\n",
    "\n",
    "    def forward(self, utterance, context):\n",
    "        if utterance.size(1) < 3:  # Si l'intervention est courte\n",
    "            return self.enhancer(torch.cat([utterance, context], dim=-1))\n",
    "        return utterance\n",
    "```\n",
    "#### **Utilisation** :\n",
    "Insérer dans `DialogueGCNModel.forward()` avant la classification :\n",
    "```python\n",
    "enhanced_features = self.context_enhancer(emotions, g_hist)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Schéma d’Intégration  \n",
    "```\n",
    "DialogueGCN (original)\n",
    "│\n",
    "├── (1) AdaptiveTemporalAttention (remplace MaskedEdgeAttention)\n",
    "│    └── Calcule des scores d’attention dynamiques\n",
    "│\n",
    "├── (2) dynamic_edge_perms (remplace edge_perms)\n",
    "│    └── Prédit la fenêtre temporelle optimale\n",
    "│\n",
    "└── (3) ContextEnhancer\n",
    "     └── Renforce les mots courts avec le contexte global\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Bénéfices Attendus  \n",
    "| Composant                 | Amélioration                     | Impact                                      |\n",
    "|---------------------------|---------------------------------|--------------------------------------------|\n",
    "| AdaptiveTemporalAttention | Attention dynamique             | Meilleure capture des dépendances longues |\n",
    "| dynamic_edge_perms        | Fenêtres adaptatives           | Réduction du biais des fenêtres fixes    |\n",
    "| ContextEnhancer          | Contexte pour mots courts      | Analyse améliorée pour \"okay\", \"oui\"    |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Validation Expérimentale  \n",
    "\n",
    "✅ **Métriques à surveiller** :  \n",
    "- Accuracy sur les interventions courtes.  \n",
    "- F1-score pour les émotions ambiguës.  \n",
    "- Temps d’entraînement (vérifier l’overhead du Transformer).  \n",
    "\n",
    "✅ **Jeu de test** :  \n",
    "- Conversations avec nombreuses interventions courtes (**DAIC-WOZ, MELD**).  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. Résumé des Fichiers Modifiés  \n",
    "\n",
    "| Fichier    | Lignes   | Modification |\n",
    "|------------|---------|--------------|\n",
    "| `models.py` | 516–616 | Nouvelle classe `AdaptiveTemporalAttention` |\n",
    "| `models.py` | 619–720 | Remplacement de `edge_perms` |\n",
    "| `models.py` | 832 (forward) | Ajout de `ContextEnhancer` |\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Étapes Suivantes  \n",
    "1. Implémenter les nouvelles classes.  \n",
    "2. Benchmark sur **MELD/IEMOCAP**.  \n",
    "3. Fine-tuning pour équilibrer performance/complexité.  \n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
