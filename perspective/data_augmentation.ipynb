{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README: Data Augmentation pour DialogueGCN\n",
    "\n",
    "## Objectif\n",
    "Améliorer les performances du modèle DialogueGCN en enrichissant le jeu de données existant grâce à des techniques de data augmentation, sans nécessiter de nouvelles annotations.\n",
    "\n",
    "---\n",
    "\n",
    "## Techniques d'Augmentation Implémentées\n",
    "\n",
    "### 1. Génération de Paraphrases avec GPT\n",
    "\n",
    "**Fichier:** `data_augmentation/paraphrase_generator.py`\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "class ParaphraseGenerator:\n",
    "    def __init__(self, model_name=\"gpt2\"):\n",
    "        self.generator = pipeline('text-generation', model=model_name)\n",
    "    \n",
    "    def generate_paraphrase(self, text, num_return_sequences=3):\n",
    "        prompt = f\"Paraphrase the following text: '{text}'\\nParaphrase:\"\n",
    "        outputs = self.generator(\n",
    "            prompt,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            max_length=len(text) + 20,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return [output['generated_text'].replace(prompt, '').strip() for output in outputs]\n",
    "```\n",
    "\n",
    "**Utilisation:**\n",
    "\n",
    "```python\n",
    "generator = ParaphraseGenerator()\n",
    "original_text = \"Okay, I understand\"\n",
    "paraphrases = generator.generate_paraphrase(original_text)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Back-Translation (Traduction Double)\n",
    "\n",
    "**Fichier:** `data_augmentation/back_translator.py`\n",
    "\n",
    "```python\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "class BackTranslator:\n",
    "    def __init__(self, intermediate_lang=\"fr\"):\n",
    "        self.intermediate_lang = intermediate_lang\n",
    "        self.to_foreign = f\"Helsinki-NLP/opus-mt-en-{intermediate_lang}\"\n",
    "        self.to_english = f\"Helsinki-NLP/opus-mt-{intermediate_lang}-en\"\n",
    "        \n",
    "        self.tokenizer_to = MarianTokenizer.from_pretrained(self.to_foreign)\n",
    "        self.model_to = MarianMTModel.from_pretrained(self.to_foreign)\n",
    "        self.tokenizer_back = MarianTokenizer.from_pretrained(self.to_english)\n",
    "        self.model_back = MarianMTModel.from_pretrained(self.to_english)\n",
    "    \n",
    "    def translate(self, text, tokenizer, model):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "        outputs = model.generate(**inputs)\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    def back_translate(self, text):\n",
    "        foreign = self.translate(text, self.tokenizer_to, self.model_to)\n",
    "        return self.translate(foreign, self.tokenizer_back, self.model_back)\n",
    "```\n",
    "\n",
    "**Utilisation:**\n",
    "\n",
    "```python\n",
    "translator = BackTranslator(intermediate_lang=\"es\")  # Espagnol comme langue intermédiaire\n",
    "augmented_text = translator.back_translate(\"Okay, I understand\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Ajout de Bruit Audio (pour données vocales)\n",
    "\n",
    "**Fichier:** `data_augmentation/audio_augmenter.py`\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "class AudioAugmenter:\n",
    "    def __init__(self, sample_rate=16000):\n",
    "        self.sample_rate = sample_rate\n",
    "    \n",
    "    def add_noise(self, audio, noise_level=0.005):\n",
    "        noise = np.random.randn(len(audio)) * noise_level\n",
    "        return audio + noise\n",
    "    \n",
    "    def time_stretch(self, audio, rate=1.1):\n",
    "        return librosa.effects.time_stretch(audio, rate=rate)\n",
    "    \n",
    "    def pitch_shift(self, audio, n_steps=2):\n",
    "        return librosa.effects.pitch_shift(audio, sr=self.sample_rate, n_steps=n_steps)\n",
    "    \n",
    "    def augment_audio(self, audio_path, output_path):\n",
    "        audio, sr = librosa.load(audio_path, sr=self.sample_rate)\n",
    "        \n",
    "        augmented = self.add_noise(audio)\n",
    "        augmented = self.time_stretch(augmented)\n",
    "        augmented = self.pitch_shift(augmented)\n",
    "        \n",
    "        librosa.output.write_wav(output_path, augmented, sr)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Intégration avec DialogueGCN\n",
    "\n",
    "### Étape 1: Préparation des Données\n",
    "Placer vos données originales dans `data/original/`\n",
    "\n",
    "Structure attendue:\n",
    "\n",
    "```\n",
    "data/original/\n",
    "├── train/\n",
    "├── dev/\n",
    "└── test/\n",
    "```\n",
    "\n",
    "### Étape 2: Exécution de l'Augmentation\n",
    "\n",
    "**Script:** `augment_data.py`\n",
    "\n",
    "```python\n",
    "from data_augmentation.paraphrase_generator import ParaphraseGenerator\n",
    "from data_augmentation.back_translator import BackTranslator\n",
    "import os\n",
    "import json\n",
    "\n",
    "def augment_dataset(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    generator = ParaphraseGenerator()\n",
    "    translator = BackTranslator()\n",
    "    \n",
    "    for split in ['train', 'dev']:  # Ne pas augmenter le test set\n",
    "        input_path = os.path.join(input_dir, split)\n",
    "        output_path = os.path.join(output_dir, split)\n",
    "        \n",
    "        for filename in os.listdir(input_path):\n",
    "            with open(os.path.join(input_path, filename)) as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            for item in data:\n",
    "                original_text = item['text']\n",
    "                \n",
    "                paraphrases = generator.generate_paraphrase(original_text, 2)\n",
    "                back_translated = translator.back_translate(original_text)\n",
    "                \n",
    "                item['augmented'] = paraphrases + [back_translated]\n",
    "            \n",
    "            with open(os.path.join(output_path, filename), 'w') as f:\n",
    "                json.dump(data, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    augment_dataset(\"data/original\", \"data/augmented\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Étape 3: Entraînement avec Données Augmentées\n",
    "\n",
    "**Modifier le DataLoader pour utiliser les données augmentées:**\n",
    "\n",
    "```python\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data = []\n",
    "        for filename in os.listdir(data_path):\n",
    "            with open(os.path.join(data_path, filename)) as f:\n",
    "                self.data.extend(json.load(f))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        if 'augmented' in item and random.random() > 0.5:\n",
    "            text = random.choice(item['augmented'])\n",
    "        else:\n",
    "            text = item['text']\n",
    "        \n",
    "        return {\n",
    "            'text': text,\n",
    "            'label': item['label'],\n",
    "            'speaker': item['speaker']\n",
    "        }\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Bonnes Pratiques\n",
    "- **Conserver les originales**: Toujours garder une copie des données originales.\n",
    "- **Équilibrer l'augmentation**: Ne pas sur-augmenter certaines classes.\n",
    "- **Valider la qualité**: Vérifier manuellement quelques exemples augmentés.\n",
    "- **Documenter**: Garder une trace des techniques utilisées et des paramètres."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
