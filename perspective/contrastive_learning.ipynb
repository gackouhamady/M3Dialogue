{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intégration d'Apprentissage Contrastif dans DialogueGCN\n",
    "\n",
    "## 1. Ajout d'une Loss Contrastive (Nouvelle classe)\n",
    "\n",
    "```python\n",
    "class ContrastiveLoss(nn.Module):   \n",
    "    def __init__(self, margin=1.0, temperature=0.5):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.temperature = temperature\n",
    "        self.cos_sim = nn.CosineSimilarity(dim=2)\n",
    "        \n",
    "    def forward(self, features, labels):\n",
    "        \"\"\"\n",
    "        features: tensor of shape (batch_size, hidden_dim)\n",
    "        labels: tensor of shape (batch_size)\n",
    "        \"\"\"\n",
    "        # Normalize features\n",
    "        features = F.normalize(features, p=2, dim=1)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        sim_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "        \n",
    "        # Create mask for positive pairs (same class)\n",
    "        label_matrix = labels.unsqueeze(1) == labels.unsqueeze(0)\n",
    "        pos_mask = label_matrix.fill_diagonal_(False)  # Exclude self-pairs\n",
    "        \n",
    "        # Create mask for negative pairs (different classes)\n",
    "        neg_mask = ~label_matrix\n",
    "        \n",
    "        # Compute positive and negative similarities\n",
    "        pos_sim = sim_matrix[pos_mask]\n",
    "        neg_sim = sim_matrix[neg_mask]\n",
    "        \n",
    "        # Contrastive loss\n",
    "        loss = -torch.log(\n",
    "            torch.exp(pos_sim).sum() / \n",
    "            (torch.exp(pos_sim).sum() + torch.exp(neg_sim).sum() + 1e-8)\n",
    "        )\n",
    "        \n",
    "        return loss\n",
    "```\n",
    "\n",
    "## 2. Modification du GraphNetwork (lignes 723-875)\n",
    "\n",
    "```python\n",
    "class GraphNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes, num_relations, max_seq_len, \n",
    "                 hidden_size=64, dropout=0.5, no_cuda=False, use_contrastive=False):\n",
    "        super(GraphNetwork, self).__init__()\n",
    "        self.use_contrastive = use_contrastive\n",
    "        \n",
    "        self.conv1 = RGCNConv(num_features, hidden_size, num_relations, num_bases=30)\n",
    "        self.conv2 = GraphConv(hidden_size, hidden_size)\n",
    "        self.matchatt = MatchingAttention(num_features+hidden_size, num_features+hidden_size, att_type='general2')\n",
    "        self.linear = nn.Linear(num_features+hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.smax_fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.no_cuda = no_cuda\n",
    "        \n",
    "        if self.use_contrastive:\n",
    "            self.projection_head = nn.Sequential(\n",
    "                nn.Linear(num_features+hidden_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, hidden_size//2)\n",
    "            )\n",
    "            self.contrastive_loss = ContrastiveLoss()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_norm, edge_type, seq_lengths, umask, nodal_attn, avec, labels=None):\n",
    "        out = self.conv1(x, edge_index, edge_type)\n",
    "        out = self.conv2(out, edge_index)\n",
    "        emotions = torch.cat([x, out], dim=-1)\n",
    "        \n",
    "        # Projection for contrastive learning\n",
    "        if self.use_contrastive and labels is not None:\n",
    "            projections = self.projection_head(emotions)\n",
    "            contrast_loss = self.contrastive_loss(projections, labels)\n",
    "        else:\n",
    "            contrast_loss = torch.tensor(0.0).to(x.device)\n",
    "        \n",
    "        log_prob = classify_node_features(emotions, seq_lengths, umask, \n",
    "                                          self.matchatt, self.linear, \n",
    "                                          self.dropout, self.smax_fc, \n",
    "                                          nodal_attn, avec, self.no_cuda)\n",
    "        \n",
    "        return log_prob, contrast_loss\n",
    "```\n",
    "\n",
    "## 3. Modification du DialogueGCNModel (lignes 878-1030)\n",
    "\n",
    "```python\n",
    "class DialogueGCNModel(nn.Module):\n",
    "    def __init__(self, ..., use_contrastive=False):\n",
    "        ...\n",
    "        self.use_contrastive = use_contrastive\n",
    "        self.graph_net = GraphNetwork(2*D_e, n_classes, n_relations, max_seq_len, \n",
    "                                      graph_hidden_size, dropout, self.no_cuda,\n",
    "                                      use_contrastive=self.use_contrastive)\n",
    "        ...\n",
    "\n",
    "    def forward(self, U, qmask, umask, seq_lengths, labels=None):\n",
    "        ...\n",
    "        log_prob, contrast_loss = self.graph_net(features, edge_index, edge_norm, \n",
    "                                                 edge_type, seq_lengths, umask, \n",
    "                                                 self.nodal_attention, self.avec,\n",
    "                                                 labels=labels)\n",
    "        \n",
    "        return log_prob, edge_index, edge_norm, edge_type, edge_index_lengths, contrast_loss\n",
    "```\n",
    "\n",
    "## 4. Modification de la fonction d'entraînement\n",
    "\n",
    "```python\n",
    "def train(model, data_loader, optimizer, device, contrastive_weight=0.5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        U, qmask, umask, seq_lengths, labels = batch\n",
    "        U, qmask, umask = U.to(device), qmask.to(device), umask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        log_prob, _, _, _, _, contrast_loss = model(U, qmask, umask, seq_lengths, labels)\n",
    "        \n",
    "        # Calculate losses\n",
    "        nll_loss = F.nll_loss(log_prob, labels)\n",
    "        \n",
    "        if model.use_contrastive:\n",
    "            loss = nll_loss + contrastive_weight * contrast_loss\n",
    "        else:\n",
    "            loss = nll_loss\n",
    "            \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)\n",
    "```\n",
    "\n",
    "## Points Clés d'Intégration\n",
    "\n",
    "### Projection Head (lignes 740-745):\n",
    "- Ajout d'un petit réseau pour projeter les features dans un espace où l'apprentissage contrastif sera appliqué\n",
    "\n",
    "### Contrastive Loss (lignes 690-720):\n",
    "- Nouvelle loss qui maximise la similarité entre échantillons de même classe\n",
    "- Minimise la similarité entre échantillons de classes différentes\n",
    "\n",
    "### Modifications du Forward Pass (lignes 750-760 et 1010-1020):\n",
    "- Retourne à la fois la loss classique et la loss contrastive\n",
    "- Permet de combiner les deux losses pendant l'entraînement\n",
    "\n",
    "### Hyperparamètre (ligne 1050):\n",
    "- `contrastive_weight` contrôle l'importance relative de la loss contrastive\n",
    "\n",
    "## Avantages pour les Émotions Proches\n",
    "\n",
    "| Critère | Amélioration |\n",
    "|----------|--------------|\n",
    "| Meilleure Séparation | Les embeddings des émotions similaires (frustration/colère) seront plus distincts |\n",
    "| Robustesse | Le modèle apprend des caractéristiques plus discriminatives |\n",
    "| Flexibilité | Le poids contrastif peut être ajusté selon le jeu de données |\n",
    "\n",
    "Cette intégration permet au modèle de mieux distinguer les émotions proches tout en conservant sa structure originale."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
