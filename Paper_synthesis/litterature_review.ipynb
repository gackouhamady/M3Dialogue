{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18faf759",
   "metadata": {},
   "source": [
    "# ğŸ“š Revue de LittÃ©rature StructurÃ©e : Emotion Recognition in Conversation (ERC)\n",
    "\n",
    "Cette revue est structurÃ©e selon trois catÃ©gories dâ€™analyse, avec une sÃ©lection pertinente dâ€™articles pour chaque type.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” Papiers fondamentaux / fondateurs (3 Ã  5)\n",
    "\n",
    "Ces travaux posent les bases du domaine de la reconnaissance des Ã©motions en conversation, y compris les premiÃ¨res formulations, les approches de fusion, et les modÃ¨les de rÃ©fÃ©rence.\n",
    "\n",
    "1. **DialogueGCN: A Graph Convolutional Neural Network for Emotion Recognition in Conversation**  \n",
    "   *Deepanway Ghosal et al., 2019*  \n",
    "   â¤ PrÃ©sente un GCN pour modÃ©liser explicitement les dÃ©pendances inter- et intra-locuteurs.  \n",
    "   [ğŸ”— Lien](https://aclanthology.org/D19-1015/)\n",
    "\n",
    "2. **MMGCN: Multimodal Fusion via Deep Graph Convolution Network for Emotion Recognition in Conversation**  \n",
    "   *Jingwen Hu et al., 2021*  \n",
    "   â¤ Fusion multimodale basÃ©e sur GCNs avec attention aux locuteurs et modalitÃ©s.  \n",
    "   [ğŸ”— Lien](https://aclanthology.org/2021.acl-long.440/)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§ª MÃ©thodes rÃ©centes ou concurrentes (5 Ã  7)\n",
    "\n",
    "Ces travaux explorent des mÃ©thodes concurrentes Ã  DialogueGCN, souvent plus rÃ©centes, avec des architectures diverses (ODEs, fusion attentive, distillation, etc.).\n",
    "\n",
    "1. **RBA-GCN: Relational Bilevel Aggregation Graph Convolutional Network for Emotion Recognition**  \n",
    "   *Lin Yuan et al., 2023*  \n",
    "   â¤ AgrÃ©gation bi-niveau relationnelle pour amÃ©liorer la prÃ©cision.  \n",
    "   [ğŸ”— Lien](https://arxiv.org/abs/2308.11029)\n",
    "\n",
    "2. **Dynamic Graph Neural ODE Network for Multi-modal Emotion Recognition in Conversation**  \n",
    "   *Yuntao Shou et al., 2024*  \n",
    "   â¤ RÃ©seau diffÃ©rentiel adaptatif pour mieux capturer les dynamiques Ã©motionnelles.  \n",
    "   [ğŸ”— Lien](https://arxiv.org/abs/2412.02935)\n",
    "\n",
    "3. **MultiEMO: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations**  \n",
    "   *Tao Shi et Shao-Lun Huang, 2023*  \n",
    "   â¤ Utilise une fusion multimodale corrÃ©lÃ©e et attentive.  \n",
    "   [ğŸ”— Lien](https://aclanthology.org/2023.acl-long.824/)\n",
    "\n",
    "4. **TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation**  \n",
    "   *Taeyang Yun et al., 2024*  \n",
    "   â¤ Fusion guidÃ©e par un modÃ¨le enseignant pour amÃ©liorer les signaux faibles.  \n",
    "   [ğŸ”— Lien](https://aclanthology.org/2024.naacl-long.5/)\n",
    "\n",
    "5. **Bi-stream Graph Learning Based Multimodal Fusion for Emotion Recognition in Conversation**  \n",
    "   *Auteur(s) non spÃ©cifiÃ©s, 2024*  \n",
    "   â¤ Apprentissage par graphes bi-flux pour une meilleure reprÃ©sentation multimodale.  \n",
    "   [ğŸ”— Lien](https://dl.acm.org/doi/10.1016/j.inffus.2024.102272)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Travaux connexes / exploratoires (3 Ã  5)\n",
    "\n",
    "Travaux qui explorent des approches proches ou complÃ©mentaires pouvant enrichir la perspective sur lâ€™ERC.\n",
    "\n",
    "1. **Emotion Recognition in Conversation Based on a Dynamic Complementary Graph Convolutional Network**  \n",
    "   *Auteur(s) non spÃ©cifiÃ©s, 2024*  \n",
    "   â¤ Graphes complÃ©mentaires dynamiques pour combler les lacunes contextuelles.  \n",
    "   [ğŸ”— Lien](https://dl.acm.org/doi/abs/10.1109/TAFFC.2024.3360979)\n",
    "\n",
    "2. **Enhancing Emotion Recognition in Conversation through Emotional Cross-Modal Fusion and Inter-class Contrastive Learning**  \n",
    "   *Haoxiang Shi et al., 2024*  \n",
    "   â¤ Fusion croisÃ©e et apprentissage contrastif entre classes pour renforcer la reprÃ©sentation Ã©motionnelle.  \n",
    "   [ğŸ”— Lien](https://arxiv.org/abs/2405.17900)\n",
    "\n",
    "---\n",
    "\n",
    "> ğŸ“ **Remarque** : tous ces articles sont rÃ©cents et ont Ã©tÃ© sÃ©lectionnÃ©s pour leur pertinence dans le cadre dâ€™un projet de Master en Machine Learning et Data Science, en lien avec lâ€™Ã©motion en conversation et la fusion multimodale.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
